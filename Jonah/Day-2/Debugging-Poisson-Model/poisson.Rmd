---
title: "Debugging models with posterior predictive checks"
author: ""
date: ""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.align="center")
```

```{r load-packages, message=FALSE, warning=FALSE}
library("ggplot2")
library("gridExtra")
library("bayesplot")
library("rstan")
```


## Load and examine data

```{r poisson-data}
source("count-data.R")
print(N)
print(y)
```

#### Make a plot of `y`

```{r plot-y}
hist(y)
```

#### Compare to random draws from a Poisson with the same mean

```{r plot-x}
x <- rpois(N, mean(y))
hist(x)
```

```{r compare-y-and-x}
par(mfrow = c(1,2))
hist(y, xlim = c(0, max(x,y)))
hist(x, xlim = c(0, max(x,y)))
par(mfrow = c(1,1))
```


## Fit basic Poisson model
```{r, fit, results="hide", warning=FALSE, message=FALSE}
fit <- stan("poisson.stan", data = c("y", "N"))
```

#### Check summary of lambda
```{r, print-fit}
print(fit, pars = "lambda")
```

#### Look at posterior distribution of lambda

```{r, plot-lambda}
lambda_draws <- as.matrix(fit, pars = "lambda")
mcmc_areas(lambda_draws, prob = 0.8) # color 80% interval
```


## Graphical posterior predictive checks

#### Extract `y_rep` draws from the fitted model object

```{r y_rep}
y_rep <- as.matrix(fit, pars = "y_rep")

# number of rows = number of post-warmup posterior draws
# number of columns = length(y)
dim(y_rep) 
```

#### Compare histogram of `y` to histograms of several `y_rep`s

```{r ppc-hist, message=FALSE}
ppc_hist(y, y_rep[1:8, ])
```

#### Compare density estimate of `y` to density estimates of a bunch of `y_rep`s

```{r ppc-dens-overlay}
ppc_dens_overlay(y, y_rep[1:50, ])
```


#### Compare proportion of zeros in `y` to the distribution of that proportion over all `y_rep`s

```{r prop-zero}
prop_zero <- function(x) mean(x == 0)
print(prop_zero(y))

ppc_stat(y, y_rep, stat = "prop_zero")
```


## Fit Poisson "hurdle" model (also with truncation from above)

This model says that there is some probability `theta` that `y`
is zero and probability `1 - theta` that `y` is positive. 
Conditional on observing a positive `y`, we use a truncated 
Poisson

```
y ~ Poisson(lambda) T[1, U]
```

where here we assume a known upper truncation point `U = max(y)`.

```{r fit-2, results="hide", message=FALSE, warning=FALSE}
mod2 <- stan_model("poisson-hurdle.stan")
fit2 <- sampling(mod2, data = c("y", "N"))
```

```{r, print-fit2}
print(fit2, pars = c("lambda", "theta"))
```

#### Compare posterior distributions of lambda from the two models
```{r, compare-lambdas}
lambda_draws2 <- as.matrix(fit2, pars = "lambda")
lambdas <- cbind(
  lambda_fit1 = lambda_draws[,1],
  lambda_fit2 = lambda_draws2[,1]
)
mcmc_areas(lambdas, prob = 0.8) # color 80% interval
```

## Posterior predictive checks again

Same plots as before, but this time using `y_rep` from `fit2`.
Everything looks much more reasonable:

```{r ppc-hist-2, message=FALSE}
y_rep2 <- as.matrix(fit2, pars = "y_rep")
ppc_hist(y, y_rep2[1:8, ])
```

```{r ppc-dens-overlay-2}
ppc_dens_overlay(y, y_rep2[1:50, ])
```

```{r, prop-zero-2, message=FALSE}
ppc_stat(y, y_rep2, stat = "prop_zero")
```
